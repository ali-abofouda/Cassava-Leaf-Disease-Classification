# ğŸŒ¿ Cassava Leaf Disease Classification

<div align="center">

![Python](https://img.shields.io/badge/Python-3.8+-3776AB?style=for-the-badge&logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
![Flask](https://img.shields.io/badge/Flask-2.0+-000000?style=for-the-badge&logo=flask&logoColor=white)
![Bootstrap](https://img.shields.io/badge/Bootstrap-5.3-7952B3?style=for-the-badge&logo=bootstrap&logoColor=white)
![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)

**A Deep Learning Solution for Automated Plant Disease Detection**

*Leveraging Transfer Learning and CNN architectures to classify Cassava leaf diseases with 84% accuracy*

[ğŸ¯ Features](#-features) â€¢ [ğŸ“Š Results](#-results) â€¢ [ğŸš€ Quick Start](#-quick-start) â€¢ [ğŸ–¥ï¸ Web App](#ï¸-web-application) â€¢ [ğŸ“ˆ Model Architecture](#-model-architecture)

</div>

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Features](#-features)
- [Disease Classes](#-disease-classes)
- [Dataset](#-dataset)
- [Model Architecture](#-model-architecture)
- [Training Pipeline](#-training-pipeline)
- [Results](#-results)
- [Web Application](#ï¸-web-application)
- [Installation](#-installation)
- [Usage](#-usage)
- [Project Structure](#-project-structure)
- [Future Improvements](#-future-improvements)
- [License](#-license)

---

## ğŸ¯ Overview

Cassava is a major food security crop in Africa, providing sustenance for over 500 million people. However, viral and bacterial diseases cause significant yield losses, threatening food security in vulnerable regions.

This project develops an **AI-powered diagnostic tool** that can identify cassava leaf diseases from smartphone images, enabling:

- ğŸŒ¾ **Early disease detection** for farmers
- ğŸ“± **Accessible diagnosis** via mobile devices
- ğŸ¯ **Accurate classification** using state-of-the-art deep learning
- ğŸŒ **Scalable solution** for agricultural communities

### Key Achievements

| Metric | Value |
|--------|-------|
| ğŸ¯ Test Accuracy | **83.83%** |
| ğŸ“‰ Test Loss | **0.519** |
| âš¡ Inference Time | **< 100ms** |
| ğŸ“¦ Model Size | **~9 MB** |
| ğŸ—ï¸ Parameters | **2.23M** (91% fewer than scratch CNN) |

---

## âœ¨ Features

### ğŸ§  Deep Learning
- **Transfer Learning** with MobileNetV2 pretrained on ImageNet
- **Custom CNN** architecture for comparison
- **Mixed Precision Training** (FP16) for faster training
- **Learning Rate Scheduling** with ReduceLROnPlateau
- **Data Augmentation** (Random Flip, Rotation, Color Jitter)
- **Weighted Sampling** for class imbalance handling

### ğŸ–¥ï¸ Web Application
- **Drag & Drop** image upload interface
- **Real-time Predictions** with confidence scores
- **Interactive Dashboard** with training metrics
- **Responsive Design** with Bootstrap 5
- **RESTful API** for integration

### ğŸ“Š Visualization
- Training & Validation curves
- Confusion matrices
- Model comparison charts
- Per-class performance analysis

---

## ğŸ¥ Disease Classes

| Class | Disease | Description | Severity |
|:-----:|---------|-------------|:--------:|
| **0** | **CBB** - Cassava Bacterial Blight | Angular leaf spots, wilting, gum exudates on stems | ğŸ”´ High |
| **1** | **CBSD** - Cassava Brown Streak Disease | Yellow/brown streaks on leaves, root necrosis | ğŸ”´ High |
| **2** | **CGM** - Cassava Green Mottle | Mosaic patterns, leaf distortion | ğŸŸ¡ Medium |
| **3** | **CMD** - Cassava Mosaic Disease | Leaf curling, mosaic patterns, stunted growth | ğŸ”´ High |
| **4** | **Healthy** | No visible disease symptoms | ğŸŸ¢ None |

---

## ğŸ“Š Dataset

The dataset is from the [Kaggle Cassava Leaf Disease Classification Competition](https://www.kaggle.com/c/cassava-leaf-disease-classification).

| Specification | Value |
|---------------|-------|
| **Total Images** | 21,397 |
| **Classes** | 5 |
| **Image Format** | JPEG |
| **Original Size** | Variable |
| **Processed Size** | 224 Ã— 224 |

### Data Split Strategy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Total Dataset (21,397)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Training (70%)    â”‚ Validation (20%)â”‚    Test (10%)       â”‚
â”‚     14,977          â”‚     4,280       â”‚      2,140          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Note:** Stratified split ensures balanced class distribution across all sets.

---

## ğŸ—ï¸ Model Architecture

### 1. CNN From Scratch

A custom convolutional neural network designed for this task:

```
Input (224Ã—224Ã—3)
    â†“
Conv2D(32) â†’ BatchNorm â†’ ReLU â†’ MaxPool
    â†“
Conv2D(64) â†’ BatchNorm â†’ ReLU â†’ MaxPool
    â†“
Conv2D(128) â†’ BatchNorm â†’ ReLU â†’ MaxPool
    â†“
Conv2D(256) â†’ BatchNorm â†’ ReLU â†’ MaxPool
    â†“
Conv2D(512) â†’ BatchNorm â†’ ReLU â†’ AdaptiveAvgPool
    â†“
Flatten â†’ Dropout(0.5) â†’ FC(256) â†’ ReLU â†’ Dropout(0.3)
    â†“
FC(5) â†’ Softmax
    â†“
Output (5 classes)
```

**Parameters:** 26,082,565

### 2. MobileNetV2 (Transfer Learning) â­

Pretrained MobileNetV2 with custom classifier head:

```
MobileNetV2 Backbone (Pretrained on ImageNet)
    â†“
Global Average Pooling
    â†“
Dropout(0.3)
    â†“
FC(5) â†’ Softmax
    â†“
Output (5 classes)
```

**Parameters:** 2,230,277 (91.4% fewer than scratch CNN!)

**Why MobileNetV2?**
- Efficient depthwise separable convolutions
- Excellent accuracy/size tradeoff
- Ideal for deployment on resource-constrained devices

---

## âš™ï¸ Training Pipeline

### Hyperparameters

| Parameter | Value | Description |
|-----------|-------|-------------|
| **Image Size** | 224 Ã— 224 | Standard input for MobileNetV2 |
| **Batch Size** | 32 | Balanced for GPU memory |
| **Epochs** | 10 | Early stopping with patience=2 |
| **Learning Rate** | 0.0001 | Adam optimizer |
| **LR Scheduler** | ReduceLROnPlateau | Factor=0.5, Patience=2 |
| **Mixed Precision** | Enabled | FP16 for faster training |
| **Random Seed** | 42 | Reproducibility |

### Data Augmentation

```python
transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomVerticalFlip(p=0.3),
    transforms.RandomRotation(20),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                        std=[0.229, 0.224, 0.225])
])
```

### Training Features

- âœ… **Mixed Precision Training** - 2x faster with torch.cuda.amp
- âœ… **Gradient Scaling** - Prevents underflow in FP16
- âœ… **Model Checkpointing** - Save best model based on validation accuracy
- âœ… **Progress Tracking** - TQDM progress bars with live metrics
- âœ… **Early Stopping** - Prevent overfitting
- âœ… **WeightedRandomSampler** - Handle class imbalance

---

## ğŸ“ˆ Results

### Model Comparison

| Metric | CNN (Scratch) | MobileNetV2 | Improvement |
|--------|:-------------:|:-----------:|:-----------:|
| **Parameters** | 26,082,565 | 2,230,277 | **-91.4%** â¬‡ï¸ |
| **Best Val Accuracy** | 66.47% | **84.93%** | **+18.46%** â¬†ï¸ |
| **Test Accuracy** | 66.31% | **83.83%** | **+17.52%** â¬†ï¸ |
| **Test Loss** | 0.8498 | **0.5192** | **-38.9%** â¬‡ï¸ |
| **Training Time** | 25.3 min | 24.4 min | -3.6% â¬‡ï¸ |

### Training Curves

<div align="center">

![Training Curves](results/training_curves.png)

*Loss and accuracy progression over 10 epochs*

</div>

### Confusion Matrix

<div align="center">

![Confusion Matrix](results/confusion_matrices.png)

*Per-class prediction accuracy*

</div>

### Model Performance Comparison

<div align="center">

![Model Comparison](results/model_comparison.png)

*Scratch CNN vs MobileNetV2 performance metrics*

</div>

### Key Insights

1. **Transfer Learning Dominance**: MobileNetV2 achieved +18% higher accuracy with 10x fewer parameters
2. **Rapid Convergence**: Pretrained features enabled faster learning
3. **Efficient Architecture**: MobileNetV2's depthwise separable convolutions provide excellent accuracy/efficiency tradeoff
4. **Robust Predictions**: Lower test loss indicates better calibrated probabilities
5. **Production Ready**: Small model size (~9MB) makes it ideal for mobile deployment

---

## ğŸ–¥ï¸ Web Application

A professional Flask web application for model deployment:

### Features

- ğŸ–¼ï¸ **Drag & Drop Upload** - Easy image submission
- ğŸ”® **Real-time Prediction** - Instant classification
- ğŸ“Š **Confidence Scores** - Probability distribution for all classes
- ğŸ“ˆ **Interactive Dashboard** - Training visualization with metrics and charts
- ğŸ¨ **Responsive Design** - Works on desktop, tablet, and mobile
- ğŸŒ **RESTful API** - Easy integration with other applications

### API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Home page with upload interface |
| `/predict` | POST | Image classification API |
| `/dashboard` | GET | Training metrics dashboard |
| `/about` | GET | Project information |
| `/api/results` | GET | Training results JSON |

### API Usage Example

```bash
# Predict disease from image
curl -X POST -F "file=@leaf_image.jpg" http://localhost:5000/predict
```

**Response:**
```json
{
  "success": true,
  "prediction": {
    "class": "CMD",
    "class_name": "Cassava Mosaic Disease",
    "confidence": 87.45,
    "description": "The most devastating viral disease...",
    "is_healthy": false,
    "all_probabilities": {
      "CBB": 2.31,
      "CBSD": 4.12,
      "CGM": 3.56,
      "CMD": 87.45,
      "Healthy": 2.56
    }
  }
}
```

---

## ğŸš€ Installation

### Prerequisites

- Python 3.8+
- CUDA-capable GPU (optional, but recommended)
- pip or conda

### Setup

1. **Clone the repository**
   ```bash
   git clone https://github.com/ali-abofouda/Cassava-Leaf-Disease-Classification.git
   cd Cassava-Leaf-Disease-Classification
   ```

2. **Create virtual environment**
   ```bash
   # Using conda
   conda create -n cassava python=3.9
   conda activate cassava

   # Or using venv
   python -m venv venv
   source venv/bin/activate  # Linux/Mac
   # or
   .\venv\Scripts\activate  # Windows
   ```

3. **Install dependencies**
   ```bash
   # For CUDA 11.8
   pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
   
   # For CPU only
   pip install torch torchvision
   
   # Install other dependencies
   pip install flask pandas matplotlib seaborn scikit-learn tqdm pillow
   ```

4. **Download the dataset** (Optional - for training)
   ```bash
   # Using Kaggle API
   kaggle competitions download -c cassava-leaf-disease-classification
   unzip cassava-leaf-disease-classification.zip -d data/
   ```

---

## ğŸ“– Usage

### Training the Model

```bash
# Run the Jupyter notebook
jupyter notebook "cassava leaf disease classification.ipynb"
```

Or train via Python script:
```bash
python train.py --epochs 10 --batch_size 32 --lr 0.0001
```

### Running the Web Application

```bash
# Start the Flask server
python app.py
```

Then open your browser and navigate to:
- **Home:** http://localhost:5000
- **Dashboard:** http://localhost:5000/dashboard
- **About:** http://localhost:5000/about

### Making Predictions (Python)

```python
from PIL import Image
import torch
from torchvision import transforms, models

# Load model
model = models.mobilenet_v2(weights=None)
model.classifier = torch.nn.Sequential(
    torch.nn.Dropout(0.3),
    torch.nn.Linear(1280, 5)
)
model.load_state_dict(torch.load('results/best_mobilenet.pth'))
model.eval()

# Prepare image
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

image = Image.open('leaf.jpg').convert('RGB')
tensor = transform(image).unsqueeze(0)

# Predict
with torch.no_grad():
    output = model(tensor)
    probabilities = torch.softmax(output, dim=1)[0]
    pred = torch.argmax(probabilities).item()
    confidence = probabilities[pred].item() * 100
    
classes = ['CBB', 'CBSD', 'CGM', 'CMD', 'Healthy']
print(f"Prediction: {classes[pred]} ({confidence:.2f}%)")
```

---

## ğŸ“ Project Structure

```
Cassava-Leaf-Disease-Classification/
â”‚
â”œâ”€â”€ ğŸ““ cassava leaf disease classification.ipynb  # Main training notebook
â”œâ”€â”€ ğŸ app.py                                      # Flask web application
â”œâ”€â”€ ğŸ“„ README.md                                   # Project documentation
â”œâ”€â”€ ğŸš« .gitignore                                  # Git ignore rules
â”‚
â”œâ”€â”€ ğŸ“ templates/                                  # HTML templates
â”‚   â”œâ”€â”€ index.html                                 # Home page (upload)
â”‚   â”œâ”€â”€ dashboard.html                             # Training metrics
â”‚   â””â”€â”€ about.html                                 # About page
â”‚
â”œâ”€â”€ ğŸ“ results/                                    # Training outputs
â”‚   â”œâ”€â”€ best_mobilenet.pth                         # Best MobileNetV2 weights
â”‚   â”œâ”€â”€ best_scratch_cnn.pth                       # Best scratch CNN weights
â”‚   â”œâ”€â”€ training_results.json                      # Metrics & history
â”‚   â”œâ”€â”€ training_curves.png                        # Loss/accuracy plots
â”‚   â”œâ”€â”€ confusion_matrices.png                     # Confusion matrices
â”‚   â””â”€â”€ model_comparison.png                       # Model comparison chart
â”‚
â”œâ”€â”€ ğŸ“ uploads/                                    # User uploaded images
â”‚   â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ ğŸ“ Test images/                                # Sample test images
â”‚   â”œâ”€â”€ CBB/
â”‚   â”œâ”€â”€ CBSD/
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ ğŸ“ data/                                       # Dataset (not in repo)
    â”œâ”€â”€ train_images/
    â”œâ”€â”€ train.csv
    â””â”€â”€ ...
```

---

## ğŸ› ï¸ Technologies Used

<div align="center">

| Category | Technologies |
|----------|--------------|
| **Deep Learning** | ![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=flat&logo=pytorch&logoColor=white) ![torchvision](https://img.shields.io/badge/torchvision-EE4C2C?style=flat&logo=pytorch&logoColor=white) |
| **Web Framework** | ![Flask](https://img.shields.io/badge/Flask-000000?style=flat&logo=flask&logoColor=white) |
| **Frontend** | ![Bootstrap](https://img.shields.io/badge/Bootstrap-7952B3?style=flat&logo=bootstrap&logoColor=white) ![HTML5](https://img.shields.io/badge/HTML5-E34F26?style=flat&logo=html5&logoColor=white) ![CSS3](https://img.shields.io/badge/CSS3-1572B6?style=flat&logo=css3&logoColor=white) |
| **Data Science** | ![Pandas](https://img.shields.io/badge/Pandas-150458?style=flat&logo=pandas&logoColor=white) ![NumPy](https://img.shields.io/badge/NumPy-013243?style=flat&logo=numpy&logoColor=white) ![scikit-learn](https://img.shields.io/badge/scikit--learn-F7931E?style=flat&logo=scikit-learn&logoColor=white) |
| **Visualization** | ![Matplotlib](https://img.shields.io/badge/Matplotlib-11557c?style=flat) ![Seaborn](https://img.shields.io/badge/Seaborn-3776AB?style=flat) |

</div>

---

## ğŸ”® Future Improvements

- [ ] **Ensemble Methods** - Combine multiple models for higher accuracy
- [ ] **Test Time Augmentation (TTA)** - Improve prediction robustness
- [ ] **K-Fold Cross Validation** - Better model validation
- [ ] **Model Quantization** - Deploy on mobile devices (TFLite/ONNX)
- [ ] **Grad-CAM Visualization** - Explainable AI with attention maps
- [ ] **Docker Containerization** - Easy deployment
- [ ] **Cloud Deployment** - AWS/GCP/Azure hosting
- [ ] **Mobile App** - React Native or Flutter application
- [ ] **Real-time Video** - Live disease detection from camera
- [ ] **Multi-language Support** - Localization for African farmers

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¤ Author

**Ali Abofouda**

- GitHub: [@ali-abofouda](https://github.com/ali-abofouda)
- LinkedIn: [Ali Ashraf](https://www.linkedin.com/in/ali-ashraf-8b619b22a/)

---

## ğŸ™ Acknowledgments

- [Kaggle](https://www.kaggle.com/c/cassava-leaf-disease-classification) for the dataset
- [PyTorch](https://pytorch.org/) team for the amazing framework
- [MobileNetV2](https://arxiv.org/abs/1801.04381) paper authors: Sandler et al.
- All contributors and supporters

---

## ğŸ“Š Project Statistics

![GitHub repo size](https://img.shields.io/github/repo-size/ali-abofouda/Cassava-Leaf-Disease-Classification?style=flat-square)
![GitHub stars](https://img.shields.io/github/stars/ali-abofouda/Cassava-Leaf-Disease-Classification?style=flat-square)
![GitHub forks](https://img.shields.io/github/forks/ali-abofouda/Cassava-Leaf-Disease-Classification?style=flat-square)
![GitHub issues](https://img.shields.io/github/issues/ali-abofouda/Cassava-Leaf-Disease-Classification?style=flat-square)

---

<div align="center">

**â­ Star this repository if you found it helpful!**

Made with â¤ï¸ and ğŸ§  Deep Learning

</div>
